# ğŸ“„ Text Summarization using Transformer

## ğŸ“Œ Overview
This project uses BART (Bidirectional and Auto-Regressive Transformers) to generate summaries from long articles. It helps in reducing reading time and improving information digestion.

## ğŸ” Problem Statement
Long articles are time-consuming to read. This project builds a model to automatically generate concise summaries using deep learning.

## ğŸ“Š Data Preprocessing & Feature Engineering
### Text Handling:
  * âœ” Loaded full articles and highlights
  * âœ” Converted to Hugging Face format
  * âœ” Tokenized using BART tokenizer

### Model Usage:
  * âœ” Used summarization pipeline
  * âœ” Generated output using BART model

## ğŸ“‚ Dataset Details
  * Dataset Name: CNN/DailyMail Articles
  * Source: Kaggle Dataset
  * Columns: id, article, highlights

## ğŸ“Š Evaluation
  * âœ” Visual comparison of generated vs. original summaries
  * âœ” ROUGE Evaluation (ROUGE-1, ROUGE-2, ROUGE-L, ROUGE-Lsum)
  * âœ” Tested on multiple articles

## ğŸ›  Technologies Used
  * Python
  * Transformers (Hugging Face)
  * Pandas
  * Evaluate (ROUGE Score)
  * Jupyter Notebook

## ğŸš€ How to Use
  * 1ï¸âƒ£ Navigate to the Text Summarization using BART folder
  * 2ï¸âƒ£ Open the Text Summarization using BART.ipynb file in Jupyter Notebook
  * 3ï¸âƒ£ Load articles, run the summarization, and check ROUGE scores

## ğŸ“Œ Use Cases
  * ğŸ“ˆ News summarization
  * ğŸ“‰ Legal or academic brief generation
  * ğŸ“š Research paper summarization
